{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines){\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines){\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignoring warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from random import randrange\n",
    "import progressbar\n",
    "from sklearn.cluster import AgglomerativeClustering as agc\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "SELECT_NUMBER = 1000\n",
    "\n",
    "random.seed(1)\n",
    "x_axis = np.arange(0, 29-1/288, 1/288).tolist()\n",
    "np_cpu = np.load(\"dataset//google-cpu-full.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_machines = pd.read_csv(\"derived_dataset//df_updated_selected_machines.csv\", header = None)\n",
    "selected_machines = selected_machines[1]\n",
    "\n",
    "# df_cpu is a dataframe with all the cpu utilisation data (columns = machine; rows = time)\n",
    "# dropping last 32 lines with corrupted data\n",
    "\n",
    "df_cpu = pd.DataFrame(np_cpu).transpose()\n",
    "df_selected_machines = df_cpu[selected_machines].drop(df_cpu.tail(32).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_cluster_map(cpu_t, number_of_cluster = 50):\n",
    "    # takes in cpu at a single time index and creates a map of cluster index to list of machine index in the cluster\n",
    "    # cpu_t is a pd.series with values of cpu at time t \n",
    "    \n",
    "    # get machine index\n",
    "    machine_index = cpu_t.columns\n",
    "    number_of_machine = len(machine_index)\n",
    "    \n",
    "    # converting cpu_t to appropriate data structure\n",
    "    cpu_t = cpu_t.mean().values.reshape(-1,1)\n",
    "    \n",
    "    # computing the clusters\n",
    "    kmeans = KMeans(n_clusters=number_of_cluster, random_state = 0)\n",
    "    clustering_output = kmeans.fit(cpu_t).labels_\n",
    "    \n",
    "    # initialising a map for clusters\n",
    "    cluster_map = {}\n",
    "    for x in range(0,number_of_cluster):\n",
    "        cluster_map[x] = []\n",
    "\n",
    "    # get a map for each cluster\n",
    "    # key is cluster index; values is list of machines in that cluster\n",
    "    for x in range(0,number_of_machine):\n",
    "        cluster_map[clustering_output[x]].append(machine_index[x])\n",
    "        \n",
    "    return cluster_map\n",
    "\n",
    "def arima_predictions(timeseries, input_arima_order = (3,0,0)):\n",
    "    # takes in a timeseries\n",
    "    # outputs a single prediction in the next timestep\n",
    "    \n",
    "    timeseries = timeseries.values\n",
    "    model = ARIMA(timeseries, order = input_arima_order)\n",
    "    model_fit = model.fit(disp=0)\n",
    "    prediction = model_fit.forecast()[0][0]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "def mse_cluster_prediction(cpu_data, input_arima_order, past_error):\n",
    "    # generate predictions for all machines in cluster at next single timestep\n",
    "    # returns a map of machine to predictions\n",
    "    \n",
    "    # get generalisation model (analogous to best_machine in correlation_prediction)\n",
    "    general_model = cpu_data.mean(axis = 1)\n",
    "    \n",
    "    # make predictions on best machine\n",
    "    general_model_prediction = arima_predictions(general_model, input_arima_order = input_arima_order)\n",
    "    \n",
    "    # get the rolling_error\n",
    "    rolling_error = past_error.mean()\n",
    "    \n",
    "    # scale general_model to fit all the other machines\n",
    "    cluster_prediction = dict()\n",
    "    for index, machine_index in enumerate(cpu_data.columns):\n",
    "        cluster_prediction[machine_index] = general_model_prediction + rolling_error[machine_index]\n",
    "        \n",
    "    return cluster_prediction    \n",
    "\n",
    "def mse_predictions(cpu_data, number_of_cluster = 50, start_time = 288, end_time = None, past_error_range = 5, rolling_cluster_window = 5):\n",
    "    ''' high level function for making predictons using the tuor framework\n",
    "\n",
    "        param:  cpu_data:   df with CPU index as columns and time-step as rows, must contain time-step for at least [start_time-3:end_time-2]\n",
    "                            ARIMA models are trained with all time-steps before the \"prediction time-step\" i.e. prediction x[n] is made using data from x[:n]\n",
    "                            Predictions are made for all machines index included in cpu_data, to exclude predicting certain machine index, drop from cpu_data\n",
    "        param:  rolling_cluster_window:     number of past values to be considered for clustering at each time-step\n",
    "        param:  number_of_cluster : number of clusters used for clustering per time-step\n",
    "        param:  start_time, end_time :  prediction is made for from start_time to (end_time - 1) inclusive\n",
    "                                     :  keep end_time = None to make predictions for the entire length of cpu_data i.e. predictions made from x[start_time:]\n",
    "        param: past_error_range  :  predictions are offset using a rolling error window of size (defined here) using past errors   \n",
    "\n",
    "    returns : df matrix of prediction with columns as machine and rows as time index\n",
    "    '''\n",
    "    \n",
    "    arima_order = (3,0,0)\n",
    "    machine_index = cpu_data.columns\n",
    "    number_of_machine = len(cpu_data.columns)\n",
    "    all_predictions = pd.DataFrame(columns = cpu_data.columns)\n",
    "    df_past_error = pd.DataFrame(0, columns = cpu_data.columns, index = np.arange(0,past_error_range))\n",
    "    \n",
    "    if end_time == None:\n",
    "        end_time = len(cpu_data.index) - 1\n",
    "    \n",
    "    with progressbar.ProgressBar(max_value = end_time-start_time) as bar:\n",
    "        for current_time in range(start_time, end_time):\n",
    "    \n",
    "            bar.update(current_time-start_time)\n",
    "        \n",
    "            # reset current prediction map\n",
    "            curr_all_machine_pred = {}\n",
    "\n",
    "            # perform clustering at current time index\n",
    "            # note clustering is only done using average of last \"rolling_cluster_window\" points\n",
    "            cluster = kmeans_cluster_map(cpu_data.iloc[current_time - rolling_cluster_window + 1: current_time + 1], \n",
    "                                         number_of_cluster = number_of_cluster)\n",
    "\n",
    "            # initialise dict for machine to prediction in current timestep\n",
    "            curr_all_machine_pred = dict()\n",
    "\n",
    "            for ls_machine_in_cluster in cluster.values():\n",
    "#                 print(\"ls_machine_in_cluster : \", ls_machine_in_cluster)\n",
    "                \n",
    "                # make predictions for all machine in each cluster\n",
    "                cluster_predictions = mse_cluster_prediction(cpu_data = cpu_data[ls_machine_in_cluster], \n",
    "                                                             input_arima_order = (3,0,0), \n",
    "                                                             past_error = df_past_error[ls_machine_in_cluster])\n",
    "            \n",
    "#                 print(\"cluster_predictions : \", cluster_predictions)\n",
    "                \n",
    "                # curr_all_machine_pred is a dict with key = machine, value = current timestep prediction\n",
    "                curr_all_machine_pred = {**curr_all_machine_pred, **cluster_predictions}\n",
    "                \n",
    "#             print(\"curr_all_machine_pred : \", curr_all_machine_pred)\n",
    "\n",
    "            # update df_past_error with most updated time index\n",
    "            # start by getting the current error\n",
    "            curr_all_machine_error = cpu_data.iloc[current_time+1] - pd.DataFrame(curr_all_machine_pred, index = [current_time+1])\n",
    "#             print(\"curr_all_machine_error : \", curr_all_machine_error)\n",
    "            \n",
    "            df_past_error = df_past_error.append(curr_all_machine_error, \n",
    "                                                 ignore_index = True)\n",
    "            df_past_error = df_past_error.drop(0).reset_index().drop(\"index\", axis = 1)\n",
    "#             print(\"df_past_error : \", df_past_error)\n",
    "            \n",
    "            # append the current predicition to all the predictions\n",
    "            current_df = pd.DataFrame(curr_all_machine_pred, index = [current_time+1])\n",
    "#             print(\"current_df : \", current_df)\n",
    "            \n",
    "            all_predictions = all_predictions.append(current_df, sort = True)\n",
    "        \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (72 of 72) |########################| Elapsed Time: 0:17:02 Time:  0:17:02\n",
      " 19% (14 of 72) |####                    | Elapsed Time: 0:02:59 ETA:   0:11:57/Users/yeehonglow/Library/Python/3.7/lib/python/site-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      " 20% (15 of 72) |#####                   | Elapsed Time: 0:03:13 ETA:   0:13:30/Users/yeehonglow/Library/Python/3.7/lib/python/site-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      " 31% (23 of 72) |#######                 | Elapsed Time: 0:05:07 ETA:   0:10:50/Users/yeehonglow/Library/Python/3.7/lib/python/site-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      " 36% (26 of 72) |########                | Elapsed Time: 0:05:50 ETA:   0:11:32/Users/yeehonglow/Library/Python/3.7/lib/python/site-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      " 81% (59 of 72) |###################     | Elapsed Time: 0:13:59 ETA:   0:02:54/Users/yeehonglow/Library/Python/3.7/lib/python/site-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "100% (72 of 72) |########################| Elapsed Time: 0:16:55 Time:  0:16:55\n",
      "  6% (5 of 72) |#                        | Elapsed Time: 0:01:09 ETA:   0:15:47/Users/yeehonglow/Library/Python/3.7/lib/python/site-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "100% (72 of 72) |########################| Elapsed Time: 0:17:12 Time:  0:17:12\n"
     ]
    }
   ],
   "source": [
    "rolling_5 = mse_predictions(df_selected_machines, \n",
    "                                   number_of_cluster = 50, \n",
    "                                   start_time = 288, \n",
    "                                   end_time = 288+72,\n",
    "                                   past_error_range = 5, \n",
    "                                   rolling_cluster_window = 5)\n",
    "\n",
    "rolling_3 = mse_predictions(df_selected_machines, \n",
    "                                   number_of_cluster = 50, \n",
    "                                   start_time = 288, \n",
    "                                   end_time = 288+72,\n",
    "                                   past_error_range = 3, \n",
    "                                   rolling_cluster_window = 3)\n",
    "\n",
    "rolling_7 = mse_predictions(df_selected_machines, \n",
    "                                   number_of_cluster = 50, \n",
    "                                   start_time = 288, \n",
    "                                   end_time = 288+72,\n",
    "                                   past_error_range = 7, \n",
    "                                   rolling_cluster_window = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014649238160274419"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((rolling_3.reset_index() - df_selected_machines[289:361].reset_index())**2).mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014942982578305135"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((rolling_5 - df_selected_machines[289:361])**2).mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01534071651013925"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((rolling_7 - df_selected_machines[289:361])**2).mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
